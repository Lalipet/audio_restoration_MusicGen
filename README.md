# Audio restoration for MusicGen
A post-generation audio restoration pipeline to enhance MusicGen audio quality through preprocessing, denoising and neural bandwidth extension

- [Open in Colab](https://colab.research.google.com/drive/1ysrfihWQQXi3MT1K-hZEwmt9mtfDzJIu?usp=sharing)

## Project Overview  
This project proposes a **post-processing restoration pipeline** that operates on generated audio without modifying the generative model itself.

The pipeline includes:
1. **Audio generation using MusicGen**: prompts are randomly selected from a list with 5 prompts per genre
2. **Peak normalization and high-pass filtering**
3. **Denoising** with noisereduce
4. **Neural bandwidth extension** using a HiFi-GANâ€“based model trained on speech, applied to music in a zero-shot setting.

The bandwidth extension stage is included as an exploratory experiment to assess the applicability of speech-trained generative BWE models to music generated by text-to-audio systems.

## Repository structure
- `code/`: Jupyter notebook containing the full generation and restoration pipeline
- `results/audio/`: Representative audio samples (raw, denoised, BWE)
- `results/spectrograms/`: Qualitative spectrogram visualizations
- `results/tables/`: Quantitative results and MOS scores

## Reproducibility
Due to the stochastic nature of generative audio models and non-deterministic GPU operations, exact waveform-level reproducibility is not expected.
Provided audio samples and visualizations should be interpreted as representative examples.

---

## References
- https://github.com/facebookresearch/audiocraft
- https://github.com/timsainb/noisereduce
- https://github.com/brentspell/hifi-gan-bwe


 ## License
This project is released under the MIT License.
